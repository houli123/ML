{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 项目1：PyTorch对MNIST手写数字数据集进行分类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、导入库和数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "CUDA是否可用? False\n",
      "当前CUDA 版本: 11.8\n",
      "11.8\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mcuda)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Storing ID of current CUDA device\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m cuda_id \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m当前CUDA ID:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA设备名称:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(cuda_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\__init__.py:878\u001b[0m, in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    313\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 314\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    318\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "print(f\"CUDA是否可用? {torch.cuda.is_available()}\")\n",
    "print(f\"当前CUDA 版本: {torch.version.cuda}\")\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"当前CUDA ID:{torch.cuda.current_device()}\")\n",
    "\n",
    "print(f\"CUDA设备名称:{torch.cuda.get_device_name(cuda_id)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install matplotlib\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/win-64/\n",
    "# !pip uninstall torch torchvision torchaudio\n",
    "import torch\n",
    "import torch.nn as nn  #神经网络的缩写，核心组件包括卷积层、池化层和全连接层。卷积层通过滤波器提取局部特征，池化层降低特征的空间维度，全连接层则用于最终的分类或回归。很常用的模块，很多网络层都是封装在这里\n",
    "# 这个模块包含了构建神经网络所需的所有核心组件。nn 模块提供了一系列的类和函数，用于构建、训练和测试神经网络。以下是一些关键组件：\n",
    "# 卷积层（Convolutional Layers）：nn.Conv2d 是一个二维卷积层，用于图像处理。它通过滤波器（也称为卷积核）在输入数据上滑动，提取局部特征。\n",
    "# 池化层（Pooling Layers）：nn.MaxPool2d 是一个最大池化层，用于降低特征图的空间维度，减少参数数量和计算量，同时保持重要的特征信息。\n",
    "# 全连接层（Fully Connected Layers）：nn.Linear 是一个全连接层，用于将特征图展平后进行分类或回归任务。\n",
    "# 激活函数（Activation Functions）：nn.ReLU、nn.Sigmoid、nn.Tanh 等，用于引入非线性，使网络能够学习复杂的模式。\n",
    "# 损失函数（Loss Functions）：nn.CrossEntropyLoss、nn.MSELoss 等，用于计算模型预测和真实标签之间的差异。\n",
    "# 优化器（Optimizers）：虽然优化器在 torch.optim 模块中，但它们通常与 nn 模块一起使用，用于更新网络权重。\n",
    "import torch.optim as optim  #优化器如SGD，Adam、Adagrad（自适应梯度）等常用优化器\n",
    "from torch.utils.data import DataLoader  #加载数据集\n",
    "from torchvision import datasets,transforms  #数据集的处理库\n",
    "import matplotlib.pyplot as plt \n",
    "# 循环神经网络（Recurrent Neural Networks，RNN）是一种能够处理序列数据的神经网络，它能够捕捉时间序列中的动态特征。LSTM结构：长短期记忆网络（Long Short-Term Memory，LSTM）是RNN的一种变体，它通过引入门控机制解决了传统RNN的长期依赖问题，能够学习长期时间依赖关系。\n",
    "\n",
    "#定义数据预处理的步骤\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),  #torch使用的是张量，将图片转换为张量\n",
    "    transforms.Normalize((0.5,),(0.5,))  #归一化处理（对数据进行标准化处理，使其均值为0.5） 左边平均值 右边方差\n",
    "])\n",
    "#加载数据集，download指定下载数据集\n",
    "train_dataset=datasets.MNIST(root='./data',train=True,transform=transform,download=True)\n",
    "test_dataset=datasets.MNIST(root='./data',train=False,transform=transform,download=True)\n",
    "\n",
    "#创建数据加载器，用于分批次加载训练数据，实现的是批量优化算法\n",
    "train_loader=DataLoader(\n",
    "    dataset=train_dataset,  #指定要加载的数据集（训练集）\n",
    "    batch_size=32,  #批处理的大小，每一次使用多少个样本用于训练，一般取2的幂次方，如32 64 128 256 512\n",
    "    shuffle=True,  #训练集一定要True进行每次打乱数据顺序\n",
    "    num_workers=2,  #使用多少个线程跑这个程序\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    dataset=test_dataset,  \n",
    "    batch_size=32,  \n",
    "    shuffle=False,  #测试集不需要打乱，可以False\n",
    "    num_workers=2,  \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、构建CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#继承nn.Module模块，一个模型包括初始化和前向传播\n",
    "class CNN(nn.Module):\n",
    "    #模型的初始化\n",
    "    def __init__(self,C=10):   #C是10个类\n",
    "        super(CNN, self).__init__()  #调用父类的初始化函数\n",
    "        self.C=C\n",
    "    # 定义卷积层\n",
    "        #下面是第一层的卷积层，由于我们的数据是一维的（黑白照片）所以通道数为1，经过这一层卷积层之后特征变为32维\n",
    "        self.conv1=nn.Conv2d(in_channels=1, #输入的通道数。\n",
    "                             out_channels=32, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        # 定义卷积层2\n",
    "        self.conv2=nn.Conv2d(in_channels=32, #要严格按照上一个网络层输出的通道大小进行设置\n",
    "                             out_channels=128, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        # 定义卷积层3\n",
    "        self.conv3=nn.Conv2d(in_channels=128, #要严格按照上一个网络层输出的通道大小进行设置\n",
    "                             out_channels=256, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        \n",
    "    # 定义第二层的激活层\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    # 定义最大池化层，一般是最大池化，池化的窗口是2X2，步长为空，这意味着特征图会缩小一半，如果原来输入的维度是[32,64,64]，则经过池化层后会变为[32,32,32]\n",
    "        # 2x2的窗口在2x2的步长下进行滑动，将2x2的窗口降为1x1，得到64个通道的图片\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=2,stride=None)  # 将2x2的窗口降为1x1\n",
    "\n",
    "        # 定义全局平均池化层，计算区域内平均值作为代表，同样降低维度，但保留的信息更为平滑。\n",
    "        self.avgpool=nn.AvgPool2d(kernel_size=7,stride=None)  #将7x7的窗口降为1x1\n",
    "\n",
    "        # 定义模型最后一层：全连接层，将最后的32x32x32的特征转化为10个类别\n",
    "        self.fc=nn.Linear(256,self.C)  # 256是输入该层的网络通道数，C是输出的网络通道类别数，即10个类别数\n",
    "        \n",
    "\n",
    "# 卷积层: 提取特征，增加通道数。例如，从 [32, 1, 28, 28] 变为 [32, 32, 28, 28]\n",
    "# 激活层: 应用非线性函数，不改变形状。例如，从 [32, 32, 28, 28] 保持为 [32, 32, 28, 28]\n",
    "# 池化层: 降低分辨率，减少计算量，保持通道数。例如，从 [32, 32, 28, 28] 变为 [32, 32, 14, 14]\n",
    "# 全连接层: 展平特征图，转换为 [批次大小, 输出特征数]。例如，从 [32, 32, 14, 14] 展平后变为 [32, 6272]\n",
    "\n",
    "    def forward(self, x):  #模型的前向传播函数，x是传进来的图片，torch.Size([32, 1, 28, 28])\n",
    "\n",
    "    #定义第一个网络层\n",
    "#### 四维张量形状：[批次大小, 通道数, 高度, 宽度]\n",
    "#### 这里32表示批次大小，32表示通道数，28表示图像高度，28表示图像宽度\n",
    "        #先卷积，增加通道数，变第二个\n",
    "        x=self.relu(self.conv1(x))   #torch.Size([32, 32, 28, 28])\n",
    "\n",
    "        #池化层，降维：目的是要变为[32,10]，即从四维张量变为二维张量，第二维（通道数）变为类别数10，用于该分类任务。\n",
    "        #其中第3第4的高度宽度就是特征的维度\n",
    "        x=self.maxpool(x)  #torch.Size([32, 32, 14, 14])\n",
    "\n",
    "    #第二个网络层\n",
    "        #卷积，增加通道数\n",
    "        x=self.relu(self.conv2(x))   #torch.Size([32, 128, 14, 14])\n",
    "        #降维，缩半\n",
    "        x=self.maxpool(x)  #torch.Size([32, 128, 7, 7])\n",
    "\n",
    "    #第三个网络层\n",
    "        x=self.relu(self.conv3(x))   #torch.Size([32, 256, 7, 7])\n",
    "        #按平均池化层kernel_size=7进行降维\n",
    "        x=self.avgpool(x)              #torch.Size([32, 256, 1, 1])\n",
    "\n",
    "        #这行代码首先通过两次 squeeze 操作去除多余的单一维度，然后将处理后的特征图传递给全连接层 self.fc。\n",
    "#这样做的目的是确保全连接层的输入维度正确，因为全连接层期望接收一个一维张量作为输入。\n",
    "        x=self.fc(x.squeeze().squeeze())\n",
    "\n",
    "        # print(x.shape)\n",
    "        # pp\n",
    "\n",
    "        return x #我们最终输出的维度是[32,10]来对每一个类别进行分类\n",
    "\n",
    "model=CNN()\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义交叉熵损失函数,常用于多分类问题\n",
    "criterion=nn.CrossEntropyLoss()    \n",
    "\n",
    "#定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam优化器收敛的速度比较快，对模型的参数parameters进行优化，学习率0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch：[1/5]，Loss：0.39\n",
      "Epoch：[2/5]，Loss：0.09\n",
      "Epoch：[3/5]，Loss：0.06\n",
      "Epoch：[4/5]，Loss：0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#反向传播：就是逆序执行的前向传播\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#首先清零所有参数的梯度，其默认情况下梯度是累加的\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()   \u001b[38;5;66;03m#必须要有\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#开启反向传播，计算损失函数关于参数的梯度\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m#根据梯度来更新参数\u001b[39;00m\n\u001b[0;32m     22\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)  \u001b[38;5;66;03m#计算的是每一个epoch的迭代数量\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs=5   #训练总周期数为5\n",
    "model.train() #启动model的训练模式\n",
    "\n",
    "for epoch in range(num_epochs):  #for循环来遍历每个训练周期\n",
    "    losses=0  #每个批处理开始都清0\n",
    "    for images,labels in train_loader:  #在每一个周期内，迭代训练数据加载器也就是每个train_loader的所有批次数据，左边是图片，右边是标签\n",
    "        #调用模型的前向传播函数，向模型model输入训练数据images，得到输出，outputs维度应该为[32,10]，32个样本，10个类别\n",
    "        outputs=model(images)\n",
    "        # print(outputs.shape)\n",
    "        # p\n",
    "\n",
    "        #损失函数\n",
    "        loss=criterion(outputs,labels)  #用交叉熵损失来计算预测输出与真是标签之间的损失值\n",
    "        losses+=loss.item()\n",
    "\n",
    "        #反向传播：就是逆序执行的前向传播\n",
    "        #首先清零所有参数的梯度，其默认情况下梯度是累加的\n",
    "        optimizer.zero_grad()   #必须要有\n",
    "        loss.backward()  #开启反向传播，计算损失函数关于参数的梯度\n",
    "        optimizer.step() #根据梯度来更新参数\n",
    "\n",
    "    avg_loss = losses/len(train_loader)  #计算的是每一个epoch的迭代数量\n",
    "    print(f'Epoch：[{epoch+1}/{num_epochs}]，Loss：{avg_loss:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、评估模型（测试集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy：98.15%\n"
     ]
    }
   ],
   "source": [
    "model.eval()   #启动model的测试模式，这个阶段就不需要反向传播了\n",
    "with torch.no_grad():  #这里不需要计算梯度，减少计算和内存的使用\n",
    "    correct=0  #正确的数量\n",
    "    total=0  # 所有图片总的数量\n",
    "    for images,labels in test_loader:  # 在每一个周期内，迭代测试数据加载器也就是每个test_loader的所有批次数据，左边是图片，右边是标签\n",
    "        outputs=model(images)  # 得到模型的输出\n",
    "        _, predicted = torch.max(outputs.data, 1)  # torch.max()函数返回每一行中最大值及其索引，返回的是每一行的最大值和每一行的最大值的下标，即预测的类别\n",
    "        total += labels.size(0)  # 累加所有图片的数量\n",
    "        correct += (predicted == labels).sum().item()  # 累加正确的数量\n",
    "\n",
    "print(f'Acuuracy：{100*correct/total:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、可视化预测的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "#定义一个函数用于显示图像及其标签和预测结果\n",
    "def imshow(img,label,predicted):\n",
    "    img=img/2+0.5  #反归一化处理，因为原始图像数据在加载时被归一化了\n",
    "    plt.imshow(img[0],cmap='gray')  #显示图像，灰度模式\n",
    "    plt.title(f\"Label：{label},Predicted：{predicted}\") \n",
    "    plt.show()\n",
    "\n",
    "#从测试数据加载器中获取一个批次的数据\n",
    "images,labels=next(iter(test_loader))\n",
    "\n",
    "#使用模型对这个批次的数据进行预测\n",
    "outputs=model(images)\n",
    "\n",
    "#得到每一行中最大值及其索引，返回的是每一行的最大值和每一行的最大值的下标，即预测的类别\n",
    "#torch.max  返回最大值及其索引，这里的_是最大值，predicted是其对应的索引\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#可视化第一个图像的预测结果\n",
    "#images[0] 是批次中的第一个图像\n",
    "# labels[0].item()  将第一个标签从张量转换为数字\n",
    "# predicted[0].item()  将第一个预测结果从张量转换为数字\n",
    "imshow(images[0],labels[0].item(),predicted[0].item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业：CIFAR-100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  #神经网络的缩写，核心组件包括卷积层、池化层和全连接层。卷积层通过滤波器提取局部特征，池化层降低特征的空间维度，全连接层则用于最终的分类或回归。很常用的模块，很多网络层都是封装在这里\n",
    "import torch.optim as optim  #优化器如SGD，Adam、Adagrad（自适应梯度）等常用优化器\n",
    "from torch.utils.data import DataLoader  #加载数据集\n",
    "from torchvision import datasets,transforms  #数据集的处理库\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#数据转换\n",
    "transform=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  #随机水平翻转图像\n",
    "    transforms.RandomCrop(32,padding=4), #随机裁剪图像\n",
    "    transforms.ToTensor(),  #将图片转换为张量\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))  #归一化处理（对数据进行标准化处理，使其均值为0.5） 左边平均值 右边方差\n",
    "])\n",
    "#加载数据集，download指定下载数据集\n",
    "train_dataset=datasets.CIFAR100(root='./data',train=True,transform=transform,download=True)\n",
    "test_dataset=datasets.CIFAR100(root='./data',train=False,transform=transform,download=True)\n",
    "\n",
    "#创建数据加载器，用于分批次加载训练数据，实现的是批量优化算法\n",
    "train_loader=DataLoader(\n",
    "    dataset=train_dataset,  #指定要加载的数据集（训练集）\n",
    "    batch_size=64,  #批处理的大小，每一次使用多少个样本用于训练，一般取2的幂次方，如32 64 128 256 512\n",
    "    shuffle=True,  #训练集一定要True进行每次打乱数据顺序\n",
    "    num_workers=2,  #使用多少个线程跑这个程序\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    dataset=test_dataset,  \n",
    "    batch_size=64,  \n",
    "    shuffle=False,  #测试集不需要打乱，可以False\n",
    "    num_workers=2,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgpool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
      "  (batchnorm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#继承nn.Module模块，一个模型包括初始化和前向传播\n",
    "class CNN(nn.Module):\n",
    "    #模型的初始化\n",
    "    def __init__(self,C=100):   \n",
    "        super(CNN, self).__init__()  #调用父类的初始化函数\n",
    "        self.C=C\n",
    "    # 定义卷积层 \n",
    "        #下面是第一层的卷积层，由于我们的数据是一维的（黑白照片）所以通道数为1，经过这一层卷积层之后特征变为32维\n",
    "        self.conv1=nn.Conv2d(in_channels=3, #输入的通道数。\n",
    "                             out_channels=32, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "#### 四维张量形状：[批次大小, 通道数, 高度, 宽度]\n",
    "#### 这里32表示批次大小，32表示通道数，28表示图像高度，28表示图像宽度\n",
    "        # # 定义卷积层2\n",
    "        self.conv2=nn.Conv2d(in_channels=32, #要严格按照上一个网络层输出的通道大小进行设置\n",
    "                             out_channels=64, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        # # 定义卷积层3\n",
    "        self.conv3=nn.Conv2d(in_channels=64, #要严格按照上一个网络层输出的通道大小进行设置\n",
    "                             out_channels=128, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        \n",
    "    # 定义第二层的激活层\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    # 定义最大池化层，一般是最大池化，池化的窗口是2X2，步长为空，这意味着特征图会缩小一半，如果原来输入的维度是[32,64,64]，则经过池化层后会变为[32,32,32]\n",
    "        # 2x2的窗口在2x2的步长下进行滑动，将2x2的窗口降为1x1，得到64个通道的图片\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=2,stride=None)  # 将2x2的窗口降为1x1\n",
    "        # 定义全局平均池化层，计算区域内平均值作为代表，同样降低维度，但保留的信息更为平滑。\n",
    "        self.avgpool=nn.AvgPool2d(kernel_size=4,stride=None)  \n",
    "        # 定义模型最后一层：全连接层，将最后的32x32x32的特征转化为10个类别\n",
    "        self.fc=nn.Linear(128,self.C)  # 256是输入该层的网络通道数，C是输出的网络通道类别数，即10个类别数\n",
    "\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)  # 添加批量归一化\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)  # 添加批量归一化\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)  # 添加批量归一化\n",
    "        \n",
    "    def forward(self, x):  #模型的前向传播函数，x是传进来的图片，torch.Size([32, 1, 28, 28])\n",
    "\n",
    "    #定义第一个网络层\n",
    "#### 四维张量形状：[批次大小, 通道数, 高度, 宽度]\n",
    "#### 这里32表示批次大小，32表示通道数，28表示图像高度，28表示图像宽度\n",
    "    #     x=self.relu(self.conv1(x))   \n",
    "    #     x=self.maxpool(x)  \n",
    "    #     # x=self.avgpool(x) \n",
    "\n",
    "    # #第二个网络层\n",
    "    #     x=self.relu(self.conv2(x))   \n",
    "    #     x=self.avgpool(x)\n",
    "    #     # x=self.maxpool(x)      \n",
    "    # #第三个网络层\n",
    "    #     x=self.relu(self.conv3(x))\n",
    "    #     # x=self.avgpool(x) \n",
    "    #     x=self.maxpool(x)          \n",
    "\n",
    "    #     x=self.fc(x.squeeze().squeeze())\n",
    "    #     # print(x.shape)\n",
    "    #     # pp\n",
    "\n",
    "        #定义第一个网络层\n",
    "        #     x=self.relu(self.conv1(x))   \n",
    "        x = self.relu(self.batchnorm1(self.conv1(x)))  # 添加批量归一化\n",
    "        x = self.maxpool(x)\n",
    "        # #第二个网络层\n",
    "        #     x=self.relu(self.conv2(x)) \n",
    "        x = self.relu(self.batchnorm2(self.conv2(x)))  # 添加批量归一化\n",
    "        x = self.avgpool(x)  \n",
    "        # #第三个网络层\n",
    "        #     x=self.relu(self.conv3(x)) \n",
    "        x = self.relu(self.batchnorm3(self.conv3(x)))  # 添加批量归一化\n",
    "        x = self.avgpool(x)  \n",
    "        x=self.fc(x.squeeze().squeeze())\n",
    "        # print(x.shape)\n",
    "        # pp\n",
    "        return x \n",
    "\n",
    "model=CNN()\n",
    "print(model)\n",
    "\n",
    "#定义交叉熵损失函数,常用于多分类问题\n",
    "criterion=nn.CrossEntropyLoss()    \n",
    "\n",
    "#定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam优化器收敛的速度比较快，对模型的参数parameters进行优化，学习率0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch：[1/5]，Loss：4.26\n",
      "Epoch：[2/5]，Loss：3.88\n",
      "Epoch：[3/5]，Loss：3.63\n",
      "Epoch：[4/5]，Loss：3.45\n",
      "Epoch：[5/5]，Loss：3.31\n"
     ]
    }
   ],
   "source": [
    "num_epochs=5   #训练总周期数为5\n",
    "model.train() #启动model的训练模式\n",
    "\n",
    "for epoch in range(num_epochs):  #for循环来遍历每个训练周期\n",
    "    losses=0  #每个批处理开始都清0\n",
    "    for images,labels in train_loader:  #在每一个周期内，迭代训练数据加载器也就是每个train_loader的所有批次数据，左边是图片，右边是标签\n",
    "        #调用模型的前向传播函数，向模型model输入训练数据images，得到输出，outputs维度应该为[32,10]，32个样本，10个类别\n",
    "        outputs=model(images)\n",
    "        # print(outputs.shape)\n",
    "        # p\n",
    "\n",
    "    #     #损失函数\n",
    "        loss=criterion(outputs,labels)  #用交叉熵损失来计算预测输出与真是标签之间的损失值\n",
    "        losses+=loss.item()\n",
    "\n",
    "    #     #反向传播：就是逆序执行的前向传播\n",
    "    #     #首先清零所有参数的梯度，其默认情况下梯度是累加的\n",
    "        optimizer.zero_grad()   #必须要有\n",
    "        loss.backward()  #开启反向传播，计算损失函数关于参数的梯度\n",
    "        optimizer.step() #根据梯度来更新参数\n",
    "\n",
    "    avg_loss = losses/len(train_loader)  #计算的是每一个epoch的迭代数量\n",
    "    print(f'Epoch：[{epoch+1}/{num_epochs}]，Loss：{avg_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy：22.17%\n"
     ]
    }
   ],
   "source": [
    "model.eval()   #启动model的测试模式，这个阶段就不需要反向传播了\n",
    "with torch.no_grad():  #这里不需要计算梯度，减少计算和内存的使用\n",
    "    correct=0  #正确的数量\n",
    "    total=0  # 所有图片总的数量\n",
    "    for images,labels in test_loader:  # 在每一个周期内，迭代测试数据加载器也就是每个test_loader的所有批次数据，左边是图片，右边是标签\n",
    "        outputs=model(images)  # 得到模型的输出\n",
    "        _, predicted = torch.max(outputs.data, 1)  # torch.max()函数返回每一行中最大值及其索引，返回的是每一行的最大值和每一行的最大值的下标，即预测的类别\n",
    "        total += labels.size(0)  # 累加所有图片的数量\n",
    "        correct += (predicted == labels).sum().item()  # 累加正确的数量\n",
    "\n",
    "print(f'Acuuracy：{100*correct/total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "#定义一个函数用于显示图像及其标签和预测结果\n",
    "def imshow(img,label,predicted):\n",
    "    img=img/2+0.5  #反归一化处理，因为原始图像数据在加载时被归一化了\n",
    "    plt.imshow(img[0],cmap='gray')  #显示图像，灰度模式\n",
    "    plt.title(f\"Label：{label},Predicted：{predicted}\") \n",
    "    plt.show()\n",
    "\n",
    "#从测试数据加载器中获取一个批次的数据\n",
    "images,labels=next(iter(test_loader))\n",
    "\n",
    "#使用模型对这个批次的数据进行预测\n",
    "outputs=model(images)\n",
    "\n",
    "#得到每一行中最大值及其索引，返回的是每一行的最大值和每一行的最大值的下标，即预测的类别\n",
    "#torch.max  返回最大值及其索引，这里的_是最大值，predicted是其对应的索引\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#可视化第一个图像的预测结果\n",
    "#images[0] 是批次中的第一个图像\n",
    "# labels[0].item()  将第一个标签从张量转换为数字\n",
    "# predicted[0].item()  将第一个预测结果从张量转换为数字\n",
    "imshow(images[0],labels[0].item(),predicted[0].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
