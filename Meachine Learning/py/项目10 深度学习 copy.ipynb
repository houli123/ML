{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 项目1：PyTorch对MNIST手写数字数据集进行分类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、导入库和数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/win-64/\n",
    "!pip uninstall torch torchvision torchaudio\n",
    "import torch\n",
    "import torch.nn as nn  #神经网络的缩写，核心组件包括卷积层、池化层和全连接层。卷积层通过滤波器提取局部特征，池化层降低特征的空间维度，全连接层则用于最终的分类或回归。很常用的模块，很多网络层都是封装在这里\n",
    "# 这个模块包含了构建神经网络所需的所有核心组件。nn 模块提供了一系列的类和函数，用于构建、训练和测试神经网络。以下是一些关键组件：\n",
    "# 卷积层（Convolutional Layers）：nn.Conv2d 是一个二维卷积层，用于图像处理。它通过滤波器（也称为卷积核）在输入数据上滑动，提取局部特征。\n",
    "# 池化层（Pooling Layers）：nn.MaxPool2d 是一个最大池化层，用于降低特征图的空间维度，减少参数数量和计算量，同时保持重要的特征信息。\n",
    "# 全连接层（Fully Connected Layers）：nn.Linear 是一个全连接层，用于将特征图展平后进行分类或回归任务。\n",
    "# 激活函数（Activation Functions）：nn.ReLU、nn.Sigmoid、nn.Tanh 等，用于引入非线性，使网络能够学习复杂的模式。\n",
    "# 损失函数（Loss Functions）：nn.CrossEntropyLoss、nn.MSELoss 等，用于计算模型预测和真实标签之间的差异。\n",
    "# 优化器（Optimizers）：虽然优化器在 torch.optim 模块中，但它们通常与 nn 模块一起使用，用于更新网络权重。\n",
    "import torch.optim as optim  #优化器如SGD，Adam、Adagrad（自适应梯度）等常用优化器\n",
    "from torch.utils.data import DataLoader  #加载数据集\n",
    "from torchvision import datasets,transforms  #数据集的处理库\n",
    "import matplotlib.pyplot as plt \n",
    "# 循环神经网络（Recurrent Neural Networks，RNN）是一种能够处理序列数据的神经网络，它能够捕捉时间序列中的动态特征。LSTM结构：长短期记忆网络（Long Short-Term Memory，LSTM）是RNN的一种变体，它通过引入门控机制解决了传统RNN的长期依赖问题，能够学习长期时间依赖关系。\n",
    "\n",
    "#定义数据预处理的步骤\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),  #torch使用的是张量，将图片转换为张量\n",
    "    transforms.Normalize((0.5,),(0.5,))  #归一化处理（对数据进行标准化处理，使其均值为0.5） 左边平均值 右边方差\n",
    "])\n",
    "#加载数据集，download指定下载数据集\n",
    "train_dataset=datasets.MNIST(root='./data',train=True,transform=transform,download=True)\n",
    "test_dataset=datasets.MNIST(root='./data',train=False,transform=transform,download=True)\n",
    "\n",
    "#创建数据加载器，用于分批次加载训练数据，实现的是批量优化算法\n",
    "train_loader=DataLoader(\n",
    "    dataset=train_dataset,  #指定要加载的数据集（训练集）\n",
    "    batch_size=32,  #批处理的大小，每一次使用多少个样本用于训练，一般取2的幂次方，如32 64 128 256 512\n",
    "    shuffle=True,  #训练集一定要True进行每次打乱数据顺序\n",
    "    num_workers=2,  #使用多少个线程跑这个程序\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    dataset=test_dataset,  \n",
    "    batch_size=32,  \n",
    "    shuffle=False,  #测试集不需要打乱，可以False\n",
    "    num_workers=2,  \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、构建CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#继承nn.Module模块，一个模型包括初始化和前向传播\n",
    "class CNN(nn.Module):\n",
    "    #模型的初始化\n",
    "    def __init__(self,C=10):   #C是10个类\n",
    "        super(CNN, self).__init__()  #调用父类的初始化函数\n",
    "        self.C=C\n",
    "    # 定义卷积层\n",
    "        #下面是第一层的卷积层，由于我们的数据是一维的（黑白照片）所以通道数为1，经过这一层卷积层之后特征变为32维\n",
    "        self.conv1=nn.Conv2d(in_channels=1, #输入的通道数。\n",
    "                             out_channels=32, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        # 定义卷积层2\n",
    "        self.conv2=nn.Conv2d(in_channels=32, #要严格按照上一个网络层输出的通道大小进行设置\n",
    "                             out_channels=128, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        # 定义卷积层3\n",
    "        self.conv3=nn.Conv2d(in_channels=128, #要严格按照上一个网络层输出的通道大小进行设置\n",
    "                             out_channels=256, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        \n",
    "    # 定义第二层的激活层\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    # 定义最大池化层，一般是最大池化，池化的窗口是2X2，步长为空，这意味着特征图会缩小一半，如果原来输入的维度是[32,64,64]，则经过池化层后会变为[32,32,32]\n",
    "        # 2x2的窗口在2x2的步长下进行滑动，将2x2的窗口降为1x1，得到64个通道的图片\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=2,stride=None)  # 将2x2的窗口降为1x1\n",
    "\n",
    "        # 定义全局平均池化层，计算区域内平均值作为代表，同样降低维度，但保留的信息更为平滑。\n",
    "        self.avgpool=nn.AvgPool2d(kernel_size=7,stride=None)  #将7x7的窗口降为1x1\n",
    "\n",
    "        # 定义模型最后一层：全连接层，将最后的32x32x32的特征转化为10个类别\n",
    "        self.fc=nn.Linear(256,self.C)  # 256是输入该层的网络通道数，C是输出的网络通道类别数，即10个类别数\n",
    "        \n",
    "\n",
    "# 卷积层: 提取特征，增加通道数。例如，从 [32, 1, 28, 28] 变为 [32, 32, 28, 28]\n",
    "# 激活层: 应用非线性函数，不改变形状。例如，从 [32, 32, 28, 28] 保持为 [32, 32, 28, 28]\n",
    "# 池化层: 降低分辨率，减少计算量，保持通道数。例如，从 [32, 32, 28, 28] 变为 [32, 32, 14, 14]\n",
    "# 全连接层: 展平特征图，转换为 [批次大小, 输出特征数]。例如，从 [32, 32, 14, 14] 展平后变为 [32, 6272]\n",
    "\n",
    "    def forward(self, x):  #模型的前向传播函数，x是传进来的图片，torch.Size([32, 1, 28, 28])\n",
    "\n",
    "    #定义第一个网络层\n",
    "#### 四维张量形状：[批次大小, 通道数, 高度, 宽度]\n",
    "#### 这里32表示批次大小，32表示通道数，28表示图像高度，28表示图像宽度\n",
    "        #先卷积，增加通道数，变第二个\n",
    "        x=self.relu(self.conv1(x))   #torch.Size([32, 32, 28, 28])\n",
    "\n",
    "        #池化层，降维：目的是要变为[32,10]，即从四维张量变为二维张量，第二维（通道数）变为类别数10，用于该分类任务。\n",
    "        #其中第3第4的高度宽度就是特征的维度\n",
    "        x=self.maxpool(x)  #torch.Size([32, 32, 14, 14])\n",
    "\n",
    "    #第二个网络层\n",
    "        #卷积，增加通道数\n",
    "        x=self.relu(self.conv2(x))   #torch.Size([32, 128, 14, 14])\n",
    "        #降维，缩半\n",
    "        x=self.maxpool(x)  #torch.Size([32, 128, 7, 7])\n",
    "\n",
    "    #第三个网络层\n",
    "        x=self.relu(self.conv3(x))   #torch.Size([32, 256, 7, 7])\n",
    "        #按平均池化层kernel_size=7进行降维\n",
    "        x=self.avgpool(x)              #torch.Size([32, 256, 1, 1])\n",
    "\n",
    "        #这行代码首先通过两次 squeeze 操作去除多余的单一维度，然后将处理后的特征图传递给全连接层 self.fc。\n",
    "#这样做的目的是确保全连接层的输入维度正确，因为全连接层期望接收一个一维张量作为输入。\n",
    "        x=self.fc(x.squeeze().squeeze())\n",
    "\n",
    "        # print(x.shape)\n",
    "        # pp\n",
    "\n",
    "        return x #我们最终输出的维度是[32,10]来对每一个类别进行分类\n",
    "\n",
    "model=CNN()\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义交叉熵损失函数,常用于多分类问题\n",
    "criterion=nn.CrossEntropyLoss()    \n",
    "\n",
    "#定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam优化器收敛的速度比较快，对模型的参数parameters进行优化，学习率0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch：[1/5]，Loss：0.37\n",
      "Epoch：[2/5]，Loss：0.09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-79d6c85f391a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m#在每一个周期内，迭代训练数据加载器也就是每个train_loader的所有批次数据，左边是图片，右边是标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#调用模型的前向传播函数，向模型model输入训练数据images，得到输出，outputs维度应该为[32,10]，32个样本，10个类别\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;31m# print(outputs.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5bb367d587f8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m#第二个网络层\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m#卷积，增加通道数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#torch.Size([32, 128, 14, 14])\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;31m#降维，缩半\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#torch.Size([32, 128, 7, 7])\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 443\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs=5   #训练总周期数为5\n",
    "model.train() #启动model的训练模式\n",
    "\n",
    "for epoch in range(num_epochs):  #for循环来遍历每个训练周期\n",
    "    losses=0  #每个批处理开始都清0\n",
    "    for images,labels in train_loader:  #在每一个周期内，迭代训练数据加载器也就是每个train_loader的所有批次数据，左边是图片，右边是标签\n",
    "        #调用模型的前向传播函数，向模型model输入训练数据images，得到输出，outputs维度应该为[32,10]，32个样本，10个类别\n",
    "        outputs=model(images)\n",
    "        # print(outputs.shape)\n",
    "        # p\n",
    "\n",
    "        #损失函数\n",
    "        loss=criterion(outputs,labels)  #用交叉熵损失来计算预测输出与真是标签之间的损失值\n",
    "        losses+=loss.item()\n",
    "\n",
    "        #反向传播：就是逆序执行的前向传播\n",
    "        #首先清零所有参数的梯度，其默认情况下梯度是累加的\n",
    "        optimizer.zero_grad()   #必须要有\n",
    "        loss.backward()  #开启反向传播，计算损失函数关于参数的梯度\n",
    "        optimizer.step() #根据梯度来更新参数\n",
    "\n",
    "    avg_loss = losses/len(train_loader)  #计算的是每一个epoch的迭代数量\n",
    "    print(f'Epoch：[{epoch+1}/{num_epochs}]，Loss：{avg_loss:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、评估模型（测试集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy：99.13%\n"
     ]
    }
   ],
   "source": [
    "model.eval()   #启动model的测试模式，这个阶段就不需要反向传播了\n",
    "with torch.no_grad():  #这里不需要计算梯度，减少计算和内存的使用\n",
    "    correct=0  #正确的数量\n",
    "    total=0  # 所有图片总的数量\n",
    "    for images,labels in test_loader:  # 在每一个周期内，迭代测试数据加载器也就是每个test_loader的所有批次数据，左边是图片，右边是标签\n",
    "        outputs=model(images)  # 得到模型的输出\n",
    "        _, predicted = torch.max(outputs.data, 1)  # torch.max()函数返回每一行中最大值及其索引，返回的是每一行的最大值和每一行的最大值的下标，即预测的类别\n",
    "        total += labels.size(0)  # 累加所有图片的数量\n",
    "        correct += (predicted == labels).sum().item()  # 累加正确的数量\n",
    "\n",
    "print(f'Acuuracy：{100*correct/total:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、可视化预测的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "#定义一个函数用于显示图像及其标签和预测结果\n",
    "def imshow(img,label,predicted):\n",
    "    img=img/2+0.5  #反归一化处理，因为原始图像数据在加载时被归一化了\n",
    "    plt.imshow(img[0],cmap='gray')  #显示图像，灰度模式\n",
    "    plt.title(f\"Label：{label},Predicted：{predicted}\") \n",
    "    plt.show()\n",
    "\n",
    "#从测试数据加载器中获取一个批次的数据\n",
    "images,labels=next(iter(test_loader))\n",
    "\n",
    "#使用模型对这个批次的数据进行预测\n",
    "outputs=model(images)\n",
    "\n",
    "#得到每一行中最大值及其索引，返回的是每一行的最大值和每一行的最大值的下标，即预测的类别\n",
    "#torch.max  返回最大值及其索引，这里的_是最大值，predicted是其对应的索引\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#可视化第一个图像的预测结果\n",
    "#images[0] 是批次中的第一个图像\n",
    "# labels[0].item()  将第一个标签从张量转换为数字\n",
    "# predicted[0].item()  将第一个预测结果从张量转换为数字\n",
    "imshow(images[0],labels[0].item(),predicted[0].item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业：CIFAR-100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  #神经网络的缩写，核心组件包括卷积层、池化层和全连接层。卷积层通过滤波器提取局部特征，池化层降低特征的空间维度，全连接层则用于最终的分类或回归。很常用的模块，很多网络层都是封装在这里\n",
    "import torch.optim as optim  #优化器如SGD，Adam、Adagrad（自适应梯度）等常用优化器\n",
    "from torch.utils.data import DataLoader  #加载数据集\n",
    "from torchvision import datasets,transforms  #数据集的处理库\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#数据转换\n",
    "transform=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  #随机水平翻转图像\n",
    "    transforms.RandomCrop(32,padding=4), #随机裁剪图像\n",
    "    transforms.ToTensor(),  #将图片转换为张量\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))  #归一化处理（对数据进行标准化处理，使其均值为0.5） 左边平均值 右边方差\n",
    "])\n",
    "#加载数据集，download指定下载数据集\n",
    "train_dataset=datasets.CIFAR100(root='./data',train=True,transform=transform,download=True)\n",
    "test_dataset=datasets.CIFAR100(root='./data',train=False,transform=transform,download=True)\n",
    "\n",
    "#创建数据加载器，用于分批次加载训练数据，实现的是批量优化算法\n",
    "train_loader=DataLoader(\n",
    "    dataset=train_dataset,  #指定要加载的数据集（训练集）\n",
    "    batch_size=64,  #批处理的大小，每一次使用多少个样本用于训练，一般取2的幂次方，如32 64 128 256 512\n",
    "    shuffle=True,  #训练集一定要True进行每次打乱数据顺序\n",
    "    num_workers=2,  #使用多少个线程跑这个程序\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    dataset=test_dataset,  \n",
    "    batch_size=64,  \n",
    "    shuffle=False,  #测试集不需要打乱，可以False\n",
    "    num_workers=2,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (avgpool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
      "  (batchnorm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#继承nn.Module模块，一个模型包括初始化和前向传播\n",
    "class CNN(nn.Module):\n",
    "    #模型的初始化\n",
    "    def __init__(self,C=100):   \n",
    "        super(CNN, self).__init__()  #调用父类的初始化函数\n",
    "        self.C=C\n",
    "    # 定义卷积层 \n",
    "        #下面是第一层的卷积层，由于我们的数据是一维的（黑白照片）所以通道数为1，经过这一层卷积层之后特征变为32维\n",
    "        self.conv1=nn.Conv2d(in_channels=3, #输入的通道数。\n",
    "                             out_channels=32, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "#### 四维张量形状：[批次大小, 通道数, 高度, 宽度]\n",
    "#### 这里32表示批次大小，32表示通道数，28表示图像高度，28表示图像宽度\n",
    "        # # 定义卷积层2\n",
    "        self.conv2=nn.Conv2d(in_channels=32, #要严格按照上一个网络层输出的通道大小进行设置\n",
    "                             out_channels=64, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        # # 定义卷积层3\n",
    "        self.conv3=nn.Conv2d(in_channels=64, #要严格按照上一个网络层输出的通道大小进行设置\n",
    "                             out_channels=128, #输出的通道数\n",
    "                             kernel_size=3,  #卷积核，一般为单数,3用的很多\n",
    "                             stride=1,  #步伐，就是卷积核（滑动）的补偿\n",
    "                             padding=1  # 在边上填充图片/特征，在边上填充0来放大图片\n",
    "                             ) \n",
    "        \n",
    "    # 定义第二层的激活层\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    # 定义最大池化层，一般是最大池化，池化的窗口是2X2，步长为空，这意味着特征图会缩小一半，如果原来输入的维度是[32,64,64]，则经过池化层后会变为[32,32,32]\n",
    "        # 2x2的窗口在2x2的步长下进行滑动，将2x2的窗口降为1x1，得到64个通道的图片\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=2,stride=None)  # 将2x2的窗口降为1x1\n",
    "        # 定义全局平均池化层，计算区域内平均值作为代表，同样降低维度，但保留的信息更为平滑。\n",
    "        self.avgpool=nn.AvgPool2d(kernel_size=4,stride=None)  \n",
    "        # 定义模型最后一层：全连接层，将最后的32x32x32的特征转化为10个类别\n",
    "        self.fc=nn.Linear(128,self.C)  # 256是输入该层的网络通道数，C是输出的网络通道类别数，即10个类别数\n",
    "\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)  # 添加批量归一化\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)  # 添加批量归一化\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)  # 添加批量归一化\n",
    "        \n",
    "    def forward(self, x):  #模型的前向传播函数，x是传进来的图片，torch.Size([32, 1, 28, 28])\n",
    "\n",
    "    #定义第一个网络层\n",
    "#### 四维张量形状：[批次大小, 通道数, 高度, 宽度]\n",
    "#### 这里32表示批次大小，32表示通道数，28表示图像高度，28表示图像宽度\n",
    "    #     x=self.relu(self.conv1(x))   \n",
    "    #     x=self.maxpool(x)  \n",
    "    #     # x=self.avgpool(x) \n",
    "\n",
    "    # #第二个网络层\n",
    "    #     x=self.relu(self.conv2(x))   \n",
    "    #     x=self.avgpool(x)\n",
    "    #     # x=self.maxpool(x)      \n",
    "    # #第三个网络层\n",
    "    #     x=self.relu(self.conv3(x))\n",
    "    #     # x=self.avgpool(x) \n",
    "    #     x=self.maxpool(x)          \n",
    "\n",
    "    #     x=self.fc(x.squeeze().squeeze())\n",
    "    #     # print(x.shape)\n",
    "    #     # pp\n",
    "\n",
    "        #定义第一个网络层\n",
    "        #     x=self.relu(self.conv1(x))   \n",
    "        x = self.relu(self.batchnorm1(self.conv1(x)))  # 添加批量归一化\n",
    "        x = self.maxpool(x)\n",
    "        # #第二个网络层\n",
    "        #     x=self.relu(self.conv2(x)) \n",
    "        x = self.relu(self.batchnorm2(self.conv2(x)))  # 添加批量归一化\n",
    "        x = self.avgpool(x)  \n",
    "        # #第三个网络层\n",
    "        #     x=self.relu(self.conv3(x)) \n",
    "        x = self.relu(self.batchnorm3(self.conv3(x)))  # 添加批量归一化\n",
    "        x = self.avgpool(x)  \n",
    "        x=self.fc(x.squeeze().squeeze())\n",
    "        # print(x.shape)\n",
    "        # pp\n",
    "        return x \n",
    "\n",
    "model=CNN()\n",
    "print(model)\n",
    "\n",
    "#定义交叉熵损失函数,常用于多分类问题\n",
    "criterion=nn.CrossEntropyLoss()    \n",
    "\n",
    "#定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam优化器收敛的速度比较快，对模型的参数parameters进行优化，学习率0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch：[1/20]，Loss：4.24\n",
      "Epoch：[2/20]，Loss：3.89\n",
      "Epoch：[3/20]，Loss：3.66\n",
      "Epoch：[4/20]，Loss：3.49\n",
      "Epoch：[5/20]，Loss：3.35\n",
      "Epoch：[6/20]，Loss：3.24\n",
      "Epoch：[7/20]，Loss：3.15\n",
      "Epoch：[8/20]，Loss：3.07\n",
      "Epoch：[9/20]，Loss：3.00\n",
      "Epoch：[10/20]，Loss：2.95\n",
      "Epoch：[11/20]，Loss：2.89\n",
      "Epoch：[12/20]，Loss：2.85\n",
      "Epoch：[13/20]，Loss：2.80\n",
      "Epoch：[14/20]，Loss：2.77\n",
      "Epoch：[15/20]，Loss：2.73\n",
      "Epoch：[16/20]，Loss：2.70\n",
      "Epoch：[17/20]，Loss：2.67\n",
      "Epoch：[18/20]，Loss：2.65\n",
      "Epoch：[19/20]，Loss：2.62\n",
      "Epoch：[20/20]，Loss：2.59\n"
     ]
    }
   ],
   "source": [
    "num_epochs=5   #训练总周期数为5\n",
    "model.train() #启动model的训练模式\n",
    "\n",
    "for epoch in range(num_epochs):  #for循环来遍历每个训练周期\n",
    "    losses=0  #每个批处理开始都清0\n",
    "    for images,labels in train_loader:  #在每一个周期内，迭代训练数据加载器也就是每个train_loader的所有批次数据，左边是图片，右边是标签\n",
    "        #调用模型的前向传播函数，向模型model输入训练数据images，得到输出，outputs维度应该为[32,10]，32个样本，10个类别\n",
    "        outputs=model(images)\n",
    "        # print(outputs.shape)\n",
    "        # p\n",
    "\n",
    "    #     #损失函数\n",
    "        loss=criterion(outputs,labels)  #用交叉熵损失来计算预测输出与真是标签之间的损失值\n",
    "        losses+=loss.item()\n",
    "\n",
    "    #     #反向传播：就是逆序执行的前向传播\n",
    "    #     #首先清零所有参数的梯度，其默认情况下梯度是累加的\n",
    "        optimizer.zero_grad()   #必须要有\n",
    "        loss.backward()  #开启反向传播，计算损失函数关于参数的梯度\n",
    "        optimizer.step() #根据梯度来更新参数\n",
    "\n",
    "    avg_loss = losses/len(train_loader)  #计算的是每一个epoch的迭代数量\n",
    "    print(f'Epoch：[{epoch+1}/{num_epochs}]，Loss：{avg_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy：44.19%\n"
     ]
    }
   ],
   "source": [
    "model.eval()   #启动model的测试模式，这个阶段就不需要反向传播了\n",
    "with torch.no_grad():  #这里不需要计算梯度，减少计算和内存的使用\n",
    "    correct=0  #正确的数量\n",
    "    total=0  # 所有图片总的数量\n",
    "    for images,labels in test_loader:  # 在每一个周期内，迭代测试数据加载器也就是每个test_loader的所有批次数据，左边是图片，右边是标签\n",
    "        outputs=model(images)  # 得到模型的输出\n",
    "        _, predicted = torch.max(outputs.data, 1)  # torch.max()函数返回每一行中最大值及其索引，返回的是每一行的最大值和每一行的最大值的下标，即预测的类别\n",
    "        total += labels.size(0)  # 累加所有图片的数量\n",
    "        correct += (predicted == labels).sum().item()  # 累加正确的数量\n",
    "\n",
    "print(f'Acuuracy：{100*correct/total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "#定义一个函数用于显示图像及其标签和预测结果\n",
    "def imshow(img,label,predicted):\n",
    "    img=img/2+0.5  #反归一化处理，因为原始图像数据在加载时被归一化了\n",
    "    plt.imshow(img[0],cmap='gray')  #显示图像，灰度模式\n",
    "    plt.title(f\"Label：{label},Predicted：{predicted}\") \n",
    "    plt.show()\n",
    "\n",
    "#从测试数据加载器中获取一个批次的数据\n",
    "images,labels=next(iter(test_loader))\n",
    "\n",
    "#使用模型对这个批次的数据进行预测\n",
    "outputs=model(images)\n",
    "\n",
    "#得到每一行中最大值及其索引，返回的是每一行的最大值和每一行的最大值的下标，即预测的类别\n",
    "#torch.max  返回最大值及其索引，这里的_是最大值，predicted是其对应的索引\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#可视化第一个图像的预测结果\n",
    "#images[0] 是批次中的第一个图像\n",
    "# labels[0].item()  将第一个标签从张量转换为数字\n",
    "# predicted[0].item()  将第一个预测结果从张量转换为数字\n",
    "imshow(images[0],labels[0].item(),predicted[0].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
