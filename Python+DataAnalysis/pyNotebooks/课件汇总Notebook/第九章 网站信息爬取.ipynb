{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第九章 网站信息爬取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python 语言发展中有一个里程碑式的应用事件，即美国谷歌（GOOGLE）公司在搜索引擎后端采用Python 语言进行链接处理和开发，这是该语言发展成熟的重要标志。Python 语言的简洁性和脚本特点非常适合链接和网页处理。  \n",
    "- 万维网（WWW）的快速发展带来了大量获取和提交网络信息的需求，这产生了“网络爬虫”等一系列应用。  \n",
    "- Python 语言提供了很多类似的函数库，包括urllib、urllib2、urllib3、wget、scrapy、<span class=\"burk\">requests</span> 等。这些库作用不同、使用方式不同、用户体验不同。  \n",
    "- 对于爬取回来的网页内容，可以通过<span class=\"burk\">re（正则表达式）</span>、<span class=\"burk\">beautifulsoup</span>4等函数库来处理，随着该领域各函数库的发展，本章将详细介绍其中最重要且最主流的两个函数库：<span class=\"burk\">requests 和beautifulsoup4</span>，它们都是第三方库。  \n",
    "- 网络爬虫应用一般分为两个步骤：（1）通过网络连接获取网页内容（2）对获得的网页内容进行处理。  \n",
    "- 这两个步骤分别使用不同的函数库：requests 和beautifulsoup4  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据来源\n",
    "- 交易数据\n",
    "- 移动通讯数据\n",
    "- 机器和传感器数据\n",
    "- <span class=\"burk\">互联网上的“开放数据”</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预备知识-浏览网页的基本过程和爬虫的基本工作原理\n",
    "### 浏览网页的过程\n",
    "- 输入网址\n",
    "- 通过DNS服务器解析域名，找到服务器对应的IP地址\n",
    "- 向服务器发送URL请求\n",
    "- 服务器相应请求，发送HTML到客户端\n",
    "- 客户端浏览器解析HTML，显示结果\n",
    "\n",
    "### 爬虫的基本工作原理\n",
    "- 获取网页HTML\n",
    "- 解析HTML，提取所需的数据\n",
    "- 数据预处理\n",
    "- 数据存储\n",
    "- 数据分析\n",
    "\n",
    "### 网页爬虫\n",
    "- 使用Python 语言实现网络爬虫和信息提交是非常简单的事情，代码行数很少，也无须知道网络通信等方面知识，非常适合非专业读者使用。然而，肆意的爬取网络数据并不是文明现象，通过程序自动提交内容争取竞争性资源也不公平。就像那些肆意的推销电话一样，他们无视接听者意愿，不仅令人讨厌也有可能引发法律纠纷。  \n",
    "- 拓展：Robots 排除协议  \n",
    "\n",
    "### 安装相关库\n",
    "- pip install requests  \n",
    "- pip install beautifulsoup4  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requests库的使用\n",
    "- requests 库是一个简洁且简单的处理HTTP请求的第三方库。  \n",
    "- requests的最大优点是程序编写过程更接近正常URL 访问过程。  \n",
    "- request 库支持非常丰富的链接访问功能，包括：国际域名和URL 获取、HTTP 长连接和连接缓存、HTTP 会话和Cookie 保持、浏览器使用风格的SSL 验证、基本的摘要认证、有效的键值对Cookie 记录、自动解压缩、自动内容解码、文件分块上传、HTTP(S)代理功能、连接超时处理、流数据下载等。  \n",
    "- requests 库中的网页请求函数get()是获取网页最常用的方式，在调用requests.get()函数后，返回的网页内容会保存为一个Response 对象，其中，get()函数的参数url 必须链接采用HTTP 或HTTPS方式访问。  \n",
    "- 通过Response 对象的属性获取网页内容。text 属性是请求的页面内容，以字符串形式展示。\n",
    "- encoding 属性非常重要，它给出了返回页面内容的编码方式，可以通过对encoding 属性赋值更改编码方式，以便于处理中文字符。    \n",
    "- Response对象的raise_for_status()方法能在非成功响应后产生异常，即只要返回的请求状态status_code 不是200，这个方法会产生一个异常，用于try…except 语句。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests的get使用举例，获取学校首页\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异常处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requests获取网页的练习\n",
    "- 豆瓣电影250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取豆瓣电影250首页\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正则表达式解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beautifulsoup4库的使用\n",
    "- beautifulsoup4 库是一个解析和处理HTML 和XML 的第三方库。  \n",
    "- 使用requests 库获取HTML 页面并将其转换成字符串后，需要进一步解析HTML页面格式，提取有用信息，这需要处理HTML 和XML 的函数库。  \n",
    "- beautifulsoup4 库，也称为Beautiful Soup 库或bs4 库，用于解析和处理HTML和XML。  \n",
    "- beautifulsoup4 库将专业的Web 页面格式解析部分封装成函数，提供了若干有用且便捷的处理函数。  \n",
    "- 可以用from…import 方式从库中直接引用BeautifulSoup 类，方法如下。  \n",
    "> from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BeautifulSoup类的常用属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以学校首页为例\n",
    "# title、a、div等标签属性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BeautifulSoup类常用的查找函数\n",
    "- find\n",
    "- find_all\n",
    "- select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### beautifulsoup4库的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取学校首页的深职要闻\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 豆瓣电影Top250数据爬取项目实战\n",
    "### 项目分析\n",
    "- 获取网页-requests\n",
    "- 解析网页-beautifulsoup4\n",
    "- 数据存储-文本文件\n",
    "- 数据输出-格式化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 项目实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相应的包\n",
    "\n",
    "# 获取网页\n",
    "\n",
    "# 数据解析\n",
    "\n",
    "# 数据存储\n",
    "\n",
    "# 数据格式化输出\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结与提高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正则表达式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests库的参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网页内容的分页处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 巩固与应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中国大学排名爬虫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 天气预报爬虫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 豆瓣读书新书快递爬虫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['喷火器', '评价人数不足', '[阿根廷] 罗伯特·阿尔特', '四川文艺出版社', '2021-1'], ['彩虹几度', '评价人数不足', '[日] 川端康成', '上海译文出版社', '2020-11'], ['恶土', '评价人数不足', '[美] 安妮·普鲁', '人民文学出版社', '2020-11'], ['乘战车的人', '评价人数不足', '[澳] 帕特里克·怀特', '浙江文艺出版社', '2021-1'], ['查泰莱夫人的情人', '未知', '(英国)  D.H.劳伦斯', '译林出版社', '2021-1'], ['我的朋友阿波罗', '7.5', '[美] 西格丽德·努涅斯', '上海译文出版社', '2020-11'], ['活在鱼缸里的她', '未知', '（英国）苏•哈伯德', '译林出版社', '2020-11'], ['沉默的病人', '未知', '[英]亚历克斯·麦克利兹', '河南文艺出版社', '2020-12-6'], ['藏狐砂冈先生', '未知', '（日）Q桑', '四川美术出版社', '2020-12-1'], ['熟年', '评价人数不足', '伊北', '中信出版集团·文艺社', '2021-1-1'], ['六十个故事', '未知', '[意] 迪诺·布扎蒂', '宝琴文化|北京联合出版公司', '2020-11-1'], ['战后风景', '评价人数不足', '[比] 菲利普·德·皮埃尔庞 编', '埃里克·朗贝 绘', '后浪丨上海文化出版社'], ['梦之囚徒：降维', '未知', '[法] 马克-安托万·马修', '后浪 | 上海文化出版社', '2020-12'], ['失落世界狂想曲', '评价人数不足', '[法] 尼古拉·德克雷西', '后浪丨湖南美术出版社', '2020-12'], ['诱惑者日记', '评价人数不足', '［丹麦］索伦•克尔凯郭尔', '外语教学与研究出版社', '2020-12'], ['致命尖端', '未知', '[美] 托马斯·品钦', '译林出版社', '2020-11'], ['火神被杀', '未知', '[日] 松本清张', '江苏凤凰文艺出版社', '2020-12'], ['伊藤润二短篇精选集', '未知', '[日] 伊藤润二', '新星出版社', '2020-12'], ['喀耳刻', '评价人数不足', '[美]马德琳·米勒（Madeline Miller）', '中信出版集团', '2021-1'], ['热带', '未知', '[日] 森见登美彦', '山东画报出版社', '2020-12'], ['可是我偏偏不喜欢', '8.5', '吴晓乐', '中国友谊出版公司', '2020-11-12'], ['珠崖', '评价人数不足', '[美] 薛爱华', '后浪×楚尘文化丨九州出版社', '2020-12'], ['铁壁之围', '评价人数不足', '[英] 亚历山大·沃森', '后浪丨九州出版社', '2020-12'], ['传染', '9.0', '[英] 亚当·库哈尔斯基', '中信出版集团', '2020-11'], ['一把海贝', '未知', '[英]托比·格林', '社会科学文献出版社', '2020-12'], ['职场妈妈生存报告', '8.2', '(美)凯特琳·柯林斯 (Caitlyn Collins)', '上海人民出版社', '世纪文景'], ['钱钟书的学术人生', '8.6', '王水照', '中华书局', '2020-11'], ['钱锺书选唐诗', '未知', '钱锺书 选', '杨绛 抄', '人民文学出版社编辑部 整理'], ['辨色视朝', '评价人数不足', '李文杰', '上海人民出版社', '2020-11'], ['一堆谎言', '评价人数不足', '[意] 米开朗基罗·安东尼奥尼', '后浪丨四川文艺出版社', '2021-1'], ['刑罚的历史', '未知', '罗翔', '云南人民出版社', '2020-12'], ['阿拉·古勒的伊斯坦布尔', '未知', '[土耳其] 阿拉·古勒 摄影  [土耳其]奥尔罕·帕慕克 序', '世纪文景|上海人民出版社', '2020-11-30'], ['我的姑姑三毛', '未知', '陈天慈', '上海文艺出版社', '2020-12'], ['尖叫的经典', '未知', '张长晓', '（冰）古尼', '中信出版集团'], ['六日战争', '未知', '[以] 迈克尔·B. 奥伦', '后浪丨九州出版社', '2020-11'], ['恶人', '未知', '[美] 詹姆斯·道斯', '上海三联书店', '2020-11'], ['照护', '未知', '[美] 凯博文', '中信出版社', '2020-11'], ['在中国大地上', '未知', '[美] 保罗·索鲁', '后浪丨九州出版社', '2020-12'], ['隋唐世界帝国的形成', '未知', '[日] 谷川道雄', '后浪×楚尘文化丨九州出版社', '2020-11'], ['优素福·卡什：镜头内外', '9.8', '[美] 戴维·特拉维斯', '后浪丨湖南美术出版社', '2020-11']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36'}\n",
    "r = requests.get(\"https://book.douban.com/latest?icn=index-latestbook-al\",headers=header)\n",
    "soup = BeautifulSoup(r.text,\"lxml\")\n",
    "names = []\n",
    "scores = []\n",
    "authors = []\n",
    "comps = []\n",
    "dates = []\n",
    "for res in soup.find_all(\"div\",class_=\"detail-frame\"):\n",
    "    names.append(res.h2.a.string)\n",
    "    score = res.p.find(\"span\",class_=\"font-small color-lightgray\").string.replace(\"\\n\",\"\")\n",
    "    if score.strip()==\"\":\n",
    "        score = \"未知\"\n",
    "    scores.append(score.strip())\n",
    "    strs = res.find(\"p\",class_=\"color-gray\").string.split(\"/\")\n",
    "    authors.append(strs[0].strip())\n",
    "    comps.append(strs[1].strip())\n",
    "    dates.append(strs[2].strip())\n",
    "results = [list(i) for i in zip(names,scores,authors,comps,dates)]\n",
    "print(results)\n",
    "# for line in results:\n",
    "#     print(\",\".join(line))\n",
    "with open(\"data/douban_books.csv\",\"w\",errors ='ignore',newline ='') as fp: \n",
    "    fp.write(\"作者,评分,作者,出版社,出版日期\\n\")\n",
    "    #csv.writer(fp).writerows(list(results))\n",
    "    for line in results:\n",
    "        fp.write(\",\".join(line)+\"\\n\")\n",
    "    #fp.close()\n",
    "#print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
